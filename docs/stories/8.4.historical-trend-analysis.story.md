# Story 8.4: Historical Trend Analysis

## Status
Draft

## Story
**As an** admin user,  
**I want** analytics and trend visualizations for policy changes,  
**so that** I can understand patterns and make data-driven decisions.

## Acceptance Criteria

1. Analytics dashboard:
   - Change frequency charts (over time)
   - Changes by route (comparison)
   - Changes by source (comparison)
   - Trend lines and patterns
2. Change frequency analysis:
   - Changes per month/week/day
   - Peak change periods
   - Seasonal patterns (if any)
3. Route and source analytics:
   - Most active routes
   - Most active sources
   - Route comparison charts
   - Source reliability metrics
4. Historical patterns:
   - Identify recurring change types
   - Pattern detection (if applicable)
   - Anomaly detection (unusual change frequency)
5. Export capabilities:
   - Export analytics data to CSV
   - Export charts to PDF/image
   - Scheduled reports (optional)
6. Time range selection:
   - Last 30 days, 90 days, 1 year, custom range
   - Compare time periods
7. Visualization options:
   - Line charts for trends
   - Bar charts for comparisons
   - Pie charts for distributions
   - Table views for detailed data
8. Performance:
   - Analytics load efficiently
   - Caching for expensive queries
   - Background processing for complex analytics
9. Manual test: View analytics dashboard, verify charts and data accuracy

## Tasks / Subtasks

- [ ] Task 1: Create analytics service (AC: 1, 2, 3, 4)
  - [ ] Create `api/services/analytics.py`
  - [ ] Implement analytics functions:
    - [ ] `get_change_frequency(start_date, end_date, group_by: str) -> List[FrequencyData]`
    - [ ] `get_changes_by_route(start_date, end_date) -> List[RouteStats]`
    - [ ] `get_changes_by_source(start_date, end_date) -> List[SourceStats]`
    - [ ] `get_most_active_routes(start_date, end_date, limit: int) -> List[RouteStats]`
    - [ ] `get_most_active_sources(start_date, end_date, limit: int) -> List[SourceStats]`
    - [ ] `detect_anomalies(start_date, end_date) -> List[Anomaly]`
  - [ ] Use efficient database queries (aggregations, indexes)
- [ ] Task 2: Create analytics API endpoints (AC: 1, 2, 3, 4)
  - [ ] Create `GET /api/analytics/change-frequency` - Change frequency over time
  - [ ] Create `GET /api/analytics/changes-by-route` - Changes grouped by route
  - [ ] Create `GET /api/analytics/changes-by-source` - Changes grouped by source
  - [ ] Create `GET /api/analytics/most-active-routes` - Most active routes
  - [ ] Create `GET /api/analytics/most-active-sources` - Most active sources
  - [ ] Create `GET /api/analytics/anomalies` - Anomaly detection
  - [ ] Accept query params: `start_date`, `end_date`, `group_by`
  - [ ] Require authentication
- [ ] Task 3: Create analytics dashboard UI (AC: 1, 6, 7)
  - [ ] Create `admin-ui/templates/pages/analytics/dashboard.html` - Analytics dashboard
  - [ ] Create web route: `GET /analytics`
  - [ ] Display analytics sections:
    - [ ] Time range selector (30 days, 90 days, 1 year, custom)
    - [ ] Change frequency chart (line chart)
    - [ ] Changes by route chart (bar chart)
    - [ ] Changes by source chart (bar chart)
    - [ ] Most active routes/sources (table or cards)
    - [ ] Anomaly detection results (if any)
  - [ ] Use charting library (Chart.js, D3.js, or similar)
- [ ] Task 4: Implement change frequency analysis (AC: 2)
  - [ ] Query PolicyChanges grouped by time period:
    - [ ] Group by day, week, or month
    - [ ] Count changes per period
    - [ ] Calculate trends
  - [ ] Identify peak periods:
    - [ ] Find periods with highest change counts
    - [ ] Calculate average change frequency
    - [ ] Highlight periods above average
  - [ ] Detect seasonal patterns (if applicable):
    - [ ] Compare same periods across years
    - [ ] Identify recurring patterns
- [ ] Task 5: Implement route and source analytics (AC: 3)
  - [ ] Query changes grouped by route:
    - [ ] Count changes per route
    - [ ] Calculate change frequency per route
    - [ ] Compare routes
  - [ ] Query changes grouped by source:
    - [ ] Count changes per source
    - [ ] Calculate source reliability (successful fetches vs failures)
    - [ ] Compare sources
  - [ ] Create comparison charts (bar charts)
- [ ] Task 6: Implement anomaly detection (AC: 4)
  - [ ] Create anomaly detection algorithm:
    - [ ] Calculate baseline change frequency
    - [ ] Detect periods with unusual frequency (statistical outliers)
    - [ ] Flag anomalies for review
  - [ ] Return anomalies with explanation
- [ ] Task 7: Implement export functionality (AC: 5)
  - [ ] Create `GET /api/analytics/export` endpoint:
    - [ ] Accept same query params as analytics endpoints
    - [ ] Generate CSV file with analytics data
    - [ ] Return CSV file download
  - [ ] Create export UI button in dashboard
  - [ ] Optional: PDF export for charts (use library like `reportlab` or `weasyprint`)
- [ ] Task 8: Implement time range selection (AC: 6)
  - [ ] Add time range picker to analytics dashboard:
    - [ ] Preset options: Last 30 days, 90 days, 1 year
    - [ ] Custom date range picker
    - [ ] Compare periods option (optional)
  - [ ] Update analytics queries based on selected range
  - [ ] Store user preference (optional)
- [ ] Task 9: Implement visualization options (AC: 7)
  - [ ] Add charting library (Chart.js recommended for simplicity):
    - [ ] Line charts for trends
    - [ ] Bar charts for comparisons
    - [ ] Pie charts for distributions
  - [ ] Add table view option:
    - [ ] Toggle between chart and table
    - [ ] Sortable, filterable table
  - [ ] Make visualizations responsive
- [ ] Task 10: Optimize performance (AC: 8)
  - [ ] Optimize database queries:
    - [ ] Use indexes on `detected_at`, `source_id`, route fields
    - [ ] Use aggregation queries (GROUP BY, COUNT)
    - [ ] Limit result sets
  - [ ] Implement caching:
    - [ ] Cache analytics results for short period (5-10 minutes)
    - [ ] Invalidate cache on new changes
    - [ ] Use Redis if available, or in-memory cache
  - [ ] Background processing for complex analytics:
    - [ ] Pre-calculate common analytics (daily job)
    - [ ] Store pre-calculated results in database
- [ ] Task 11: Create analytics data models (AC: 1, 2, 3)
  - [ ] Create Pydantic schemas for analytics responses:
    - [ ] `FrequencyData` - Change frequency over time
    - [ ] `RouteStats` - Route statistics
    - [ ] `SourceStats` - Source statistics
    - [ ] `Anomaly` - Anomaly detection result
  - [ ] Use for API response validation
- [ ] Task 12: Manual testing (AC: 9)
  - [ ] Test: View analytics dashboard
  - [ ] Test: Select different time ranges
  - [ ] Test: Verify charts display correctly
  - [ ] Test: Verify data accuracy
  - [ ] Test: Export analytics data
  - [ ] Test: Performance with large datasets

## Dev Notes

### Previous Story Insights
- Story 1.2 created PolicyChange model
- Story 2.9 created change detection pipeline
- Story 6.3 created basic read-only dashboard
- Story 4.2 created dashboard with statistics

### PolicyChange Model
[Source: docs/architecture/data-models.md]

**PolicyChange Attributes:**
- `id`: UUID
- `sourceId`: UUID
- `detectedAt`: Date (for time-based analysis)
- `diff`: string
- Can join with RouteSubscription for route analysis
- Can join with Source for source analysis

### Database Queries
**Efficient Analytics Queries:**
- Use SQL aggregation functions (COUNT, GROUP BY)
- Use indexes on `detected_at`, `source_id`
- Use date range filtering
- Consider materialized views for complex analytics (future)

### File Locations
[Source: docs/architecture/unified-project-structure.md]

Files to create:
- `api/services/analytics.py` - Analytics service
- `api/models/schemas/analytics.py` - Analytics response schemas
- `admin-ui/templates/pages/analytics/dashboard.html` - Analytics dashboard
- `admin-ui/static/js/analytics.js` - Analytics JavaScript (charts)
- `tests/unit/test_services/test_analytics.py` - Unit tests
- `tests/integration/test_services/test_analytics.py` - Integration tests

### Coding Standards
[Source: docs/architecture/coding-standards.md]

**Database Queries:**
- Use efficient aggregation queries
- Use indexes for performance
- Cache expensive queries

### Testing Requirements
[Source: docs/architecture/testing-strategy.md]

**Integration Tests:**
- Test analytics queries with real data
- Test chart generation
- Test export functionality

**Performance Tests:**
- Test with large datasets
- Verify query performance
- Verify caching works

## Testing

**Integration Tests:**
- Test analytics queries
- Test chart generation
- Test export functionality

**Performance Tests:**
- Test with large datasets
- Verify query performance
- Verify caching

**Manual Testing:**
- View analytics dashboard
- Test time range selection
- Verify charts and data accuracy
- Test export functionality

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-27 | 1.0 | Initial story creation | Bob (Scrum Master) |



