# Story 7.2: NLP Summarization Engine

## Status
Draft

## Story
**As an** admin user,  
**I want** plain-language summaries of policy changes,  
**so that** I can quickly understand what changed without reading raw diffs.

## Acceptance Criteria

1. Summarization function:
   - Takes PolicyChange diff as input
   - Calls OpenRouter API to generate summary
   - Returns plain-language summary (2-3 sentences)
2. Summary quality:
   - Summaries are clear and concise
   - Focus on key changes (what, why, impact)
   - Avoid legal interpretation (information only)
   - Use simple, non-technical language
3. Summary storage:
   - Add `ai_summary` field to PolicyChange table (nullable)
   - Store summary with PolicyChange record
   - Timestamp when summary was generated
4. Summary generation workflow:
   - Generate summary when change is detected (optional, can be async)
   - Or generate on-demand when user requests
   - Cache summaries (don't regenerate if already exists)
5. Summary validation:
   - Check summary length (not too long or too short)
   - Validate summary contains meaningful content
   - Flag summaries that may need review
6. Fallback handling:
   - If summarization fails, use raw diff preview
   - Log failures for monitoring
   - Don't block change detection if summarization fails
7. Unit tests for summarization logic
8. Integration test: Generate summary for sample change, verify quality

## Tasks / Subtasks

- [ ] Task 1: Create summarization service (AC: 1)
  - [ ] Create `api/services/ai_summarization.py`
  - [ ] Implement `generate_summary(policy_change: PolicyChange) -> str` function:
    - [ ] Extract diff text from PolicyChange
    - [ ] Create prompt for OpenRouter API
    - [ ] Call OpenRouter API via integration layer
    - [ ] Extract summary from API response
    - [ ] Return summary text
  - [ ] Handle errors gracefully (return None on failure)
- [ ] Task 2: Create summarization prompt template (AC: 1, 2)
  - [ ] Design prompt for policy change summarization:
    - [ ] Context: "Summarize the following policy change diff"
    - [ ] Instructions: "Focus on key changes, what changed, why it might matter"
    - [ ] Constraints: "2-3 sentences, plain language, no legal interpretation"
    - [ ] Include diff text in prompt
  - [ ] Store prompt template in code or configuration
  - [ ] Make prompt configurable (for A/B testing)
- [ ] Task 3: Add ai_summary field to PolicyChange (AC: 3)
  - [ ] Create Alembic migration:
    - [ ] Add `ai_summary` column to `policy_changes` table (TEXT, nullable)
    - [ ] Add `ai_summary_generated_at` column (TIMESTAMP WITH TIME ZONE, nullable)
    - [ ] Add `ai_summary_model` column (VARCHAR(100), nullable) - store model used
  - [ ] Update SQLAlchemy model: `api/models/db/policy_change.py`
  - [ ] Update Pydantic schemas: `api/models/schemas/policy_change.py`
- [ ] Task 4: Implement summary generation workflow (AC: 4)
  - [ ] Option 1: Generate on change detection (async):
    - [ ] Update `fetch_and_process_source()` pipeline
    - [ ] After PolicyChange created, trigger async summary generation
    - [ ] Use background task or queue (optional)
  - [ ] Option 2: Generate on-demand:
    - [ ] Create `POST /api/changes/{id}/generate-summary` endpoint
    - [ ] Generate summary when user requests
    - [ ] Return summary or error
  - [ ] Implement caching:
    - [ ] Check if `ai_summary` already exists
    - [ ] Don't regenerate if summary exists
    - [ ] Allow force regeneration (optional parameter)
- [ ] Task 5: Implement summary validation (AC: 5)
  - [ ] Create validation function:
    - [ ] Check summary length (min 50 chars, max 500 chars)
    - [ ] Check summary is not empty
    - [ ] Check summary contains meaningful content (not just "No changes" or error messages)
    - [ ] Flag summaries that may need review
  - [ ] Store validation status (optional field)
  - [ ] Log validation results
- [ ] Task 6: Implement fallback handling (AC: 6)
  - [ ] If summarization fails:
    - [ ] Log error (use Python `logging`)
    - [ ] Return None from summarization function
    - [ ] Don't store summary in database
    - [ ] Don't block change detection pipeline
  - [ ] If summary validation fails:
    - [ ] Log warning
    - [ ] Store summary but flag for review
    - [ ] Or don't store and log error
- [ ] Task 7: Create summary generation API endpoint (AC: 4)
  - [ ] Create `POST /api/changes/{id}/generate-summary` endpoint
  - [ ] Accept PolicyChange ID
  - [ ] Generate summary using summarization service
  - [ ] Store summary in database
  - [ ] Return summary or error
  - [ ] Require authentication
- [ ] Task 8: Integrate with change detection pipeline (AC: 4)
  - [ ] Update `api/services/pipeline.py` or change detection service
  - [ ] After PolicyChange created:
    - [ ] Check if AI features enabled (feature flag)
    - [ ] Trigger summary generation (async or sync)
    - [ ] Don't block pipeline if summarization fails
  - [ ] Make integration optional (feature flag)
- [ ] Task 9: Create unit tests (AC: 7)
  - [ ] Create `tests/unit/test_services/test_ai_summarization.py`
  - [ ] Test: generate_summary with mock OpenRouter API
  - [ ] Test: summary validation
  - [ ] Test: fallback handling (API failure)
  - [ ] Test: caching (don't regenerate if exists)
  - [ ] Use `pytest` and `pytest-mock`
- [ ] Task 10: Create integration test (AC: 8)
  - [ ] Create `tests/integration/test_services/test_summarization.py`
  - [ ] Test: generate summary for sample PolicyChange
  - [ ] Verify summary quality (length, content)
  - [ ] Verify summary stored in database
  - [ ] Verify summary generation timestamp
  - [ ] Use test OpenRouter API key

## Dev Notes

### Previous Story Insights
- Story 7.1 created OpenRouter API integration
- Story 2.7 created text diff generation (PolicyChange.diff field)
- Story 2.9 created end-to-end fetch pipeline
- Story 1.2 created PolicyChange database model

### OpenRouter API Integration
[Source: docs/stories/7.1.openrouter-api-integration-and-infrastructure.story.md]

**OpenRouter Client:**
- `api/integrations/openrouter.py` - OpenRouter API client
- `generate_completion(prompt: str, model: str, **kwargs) -> CompletionResult`
- Returns text, token counts, and metadata
- Handles errors and retries

**Usage:**
- Use OpenAI-compatible interface
- Set base URL to OpenRouter
- Specify model (e.g., `anthropic/claude-3-opus`, `openai/gpt-4`)
- Track token usage and costs

### PolicyChange Model
[Source: docs/architecture/data-models.md]

**PolicyChange Attributes:**
- `id`: UUID
- `sourceId`: UUID
- `detectedAt`: Date
- `diff`: string (text diff from Story 2.7)
- `oldVersionId`: UUID
- `newVersionId`: UUID

**New Fields:**
- `ai_summary`: string (nullable) - AI-generated summary
- `ai_summary_generated_at`: Date (nullable) - When summary was generated
- `ai_summary_model`: string (nullable) - Model used for generation

### Summarization Prompt Design
**Prompt Template:**
```
You are a helpful assistant that summarizes policy changes for immigration documents.

Given the following policy change diff, provide a clear, concise summary in 2-3 sentences.

Focus on:
- What changed (key modifications)
- Why it might matter (potential impact)
- Use plain, non-technical language
- Avoid legal interpretation (information only)

Policy Change Diff:
{diff_text}

Summary:
```

**Model Selection:**
- Use high-quality models via OpenRouter (e.g., `anthropic/claude-3-opus`, `openai/gpt-4`)
- Consider cost vs quality tradeoff
- Make model configurable

### File Locations
[Source: docs/architecture/unified-project-structure.md]

Files to create:
- `api/services/ai_summarization.py` - Summarization service
- `api/models/db/policy_change.py` - Update with ai_summary fields
- `api/models/schemas/policy_change.py` - Update schemas
- `tests/unit/test_services/test_ai_summarization.py` - Unit tests
- `tests/integration/test_services/test_summarization.py` - Integration tests
- `alembic/versions/XXX_add_ai_summary_to_policy_changes.py` - Migration

### Coding Standards
[Source: docs/architecture/coding-standards.md]

**Service Layer:**
- Always use service layer for business logic
- Never call external APIs directly from route handlers
- Use async/await for all async operations
- Handle errors gracefully

**Error Handling:**
- Don't block change detection if summarization fails
- Log all errors for monitoring
- Return None or error status on failure

### Testing Requirements
[Source: docs/architecture/testing-strategy.md]

**Unit Tests:**
- Test summarization logic with mock API
- Test validation logic
- Test fallback handling
- Test caching

**Integration Tests:**
- Test with real OpenRouter API (test key)
- Verify summary quality
- Verify database storage

### Technical Constraints
- Summaries must be 2-3 sentences (50-500 characters)
- Must not block change detection pipeline
- Must handle API failures gracefully
- Must cache summaries (don't regenerate)
- Must track which model was used

## Testing

**Unit Tests:**
- Test generate_summary with mock OpenRouter API
- Test summary validation
- Test fallback handling (API failure)
- Test caching (don't regenerate if exists)

**Integration Tests:**
- Generate summary for sample PolicyChange
- Verify summary quality (length, content)
- Verify summary stored in database
- Verify summary generation timestamp

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-27 | 1.0 | Initial story creation | Bob (Scrum Master) |

