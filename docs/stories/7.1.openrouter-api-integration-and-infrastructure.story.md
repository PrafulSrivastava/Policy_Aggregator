# Story 7.1: OpenRouter API Integration & Infrastructure

## Status
Draft

## Story
**As a** developer,  
**I want** to integrate OpenRouter API for AI-powered summarization,  
**so that** I can generate plain-language summaries of policy changes using a unified LLM interface.

## Acceptance Criteria

1. OpenRouter API provider integrated:
   - OpenRouter API client library integrated
   - API key management (environment variables, secure storage)
   - OpenAI-compatible SDK support
2. API abstraction layer:
   - Provider-agnostic interface
   - Can switch providers if needed (OpenRouter supports multiple models)
   - Error handling for API failures
3. Cost monitoring:
   - Track API usage and costs
   - Log all API calls with token counts
   - Cost alerts if usage exceeds thresholds
4. Rate limiting:
   - Respect OpenRouter API rate limits
   - Implement retry logic with exponential backoff
   - Queue system for high-volume requests (if needed)
5. Configuration:
   - OpenRouter API endpoint configuration
   - Model selection (via OpenRouter, e.g., GPT-4, Claude, etc.)
   - Temperature and other parameters configurable
6. Error handling:
   - Graceful degradation if API unavailable
   - Fallback to raw diff if summarization fails
   - Clear error logging
7. Unit tests for API integration
8. Integration test: Call OpenRouter API with sample policy change, verify response

## Tasks / Subtasks

- [ ] Task 1: Install OpenRouter client library (AC: 1)
  - [ ] Install `openai` Python SDK (OpenRouter is OpenAI-compatible)
  - [ ] Or install OpenRouter-specific client if available
  - [ ] Add to `requirements.txt`
  - [ ] Document OpenRouter API key setup in README
- [ ] Task 2: Create OpenRouter API client (AC: 1, 2)
  - [ ] Create `api/integrations/openrouter.py`
  - [ ] Create OpenRouter client abstraction:
    - [ ] Initialize client with API key from environment (`OPENROUTER_API_KEY`)
    - [ ] Use OpenAI-compatible interface (base URL: `https://openrouter.ai/api/v1`)
    - [ ] Implement `generate_completion(prompt: str, model: str, **kwargs) -> CompletionResult` function
    - [ ] Return `CompletionResult` with text, token counts, and metadata
  - [ ] Design abstraction to allow switching providers/models
- [ ] Task 3: Implement error handling (AC: 2, 6)
  - [ ] Add try-except blocks for API errors
  - [ ] Handle network errors (timeout, connection errors)
  - [ ] Handle API errors (rate limits, authentication, invalid requests)
  - [ ] Handle response parsing errors
  - [ ] Return error status in `CompletionResult` on failure
  - [ ] Add logging for errors (use Python `logging` module)
- [ ] Task 4: Implement retry logic with exponential backoff (AC: 4)
  - [ ] Implement retry decorator or function
  - [ ] Retry on transient failures (network errors, rate limits)
  - [ ] Use exponential backoff (1s, 2s, 4s delays)
  - [ ] Maximum 3 retries
  - [ ] Don't retry on permanent failures (authentication errors, invalid requests)
- [ ] Task 5: Implement rate limiting (AC: 4)
  - [ ] Research OpenRouter rate limits (check documentation)
  - [ ] Implement rate limiting logic:
    - [ ] Track API calls per time window
    - [ ] Queue requests if rate limit exceeded
    - [ ] Respect rate limit headers from API responses
  - [ ] Add rate limit monitoring and logging
- [ ] Task 6: Implement cost monitoring (AC: 3)
  - [ ] Create `api/models/db/llm_api_usage.py` - LLM API usage tracking model
  - [ ] Create Alembic migration for `llm_api_usage` table:
    - [ ] `id`: UUID (primary key)
    - [ ] `model`: VARCHAR(100) (model used)
    - [ ] `provider`: VARCHAR(50) (OpenRouter)
    - [ ] `prompt_tokens`: INTEGER
    - [ ] `completion_tokens`: INTEGER
    - [ ] `total_tokens`: INTEGER
    - [ ] `cost_usd`: DECIMAL (calculated cost)
    - [ ] `request_id`: VARCHAR(255) (OpenRouter request ID)
    - [ ] `created_at`: TIMESTAMP WITH TIME ZONE
  - [ ] Log all API calls with token counts
  - [ ] Calculate costs based on OpenRouter pricing
  - [ ] Store usage records in database
- [ ] Task 7: Implement cost alerts (AC: 3)
  - [ ] Create cost monitoring service
  - [ ] Calculate daily/monthly costs
  - [ ] Check against thresholds (configurable)
  - [ ] Send alerts if usage exceeds thresholds (email to admin)
  - [ ] Add cost alert configuration (thresholds, alert recipients)
- [ ] Task 8: Add configuration support (AC: 5)
  - [ ] Update `api/config.py`:
    - [ ] `OPENROUTER_API_KEY`: API key from environment
    - [ ] `OPENROUTER_BASE_URL`: Base URL (default: `https://openrouter.ai/api/v1`)
    - [ ] `OPENROUTER_DEFAULT_MODEL`: Default model (e.g., `anthropic/claude-3-opus`)
    - [ ] `OPENROUTER_TEMPERATURE`: Temperature parameter (default: 0.7)
    - [ ] `OPENROUTER_MAX_TOKENS`: Max tokens (default: 500)
  - [ ] Add configuration to `.env.example`
  - [ ] Document configuration options
- [ ] Task 9: Implement graceful degradation (AC: 6)
  - [ ] Add fallback logic if API unavailable:
    - [ ] Return error status in `CompletionResult`
    - [ ] Log error for monitoring
    - [ ] Don't block change detection if summarization fails
  - [ ] Add health check for OpenRouter API
  - [ ] Add feature flag to enable/disable AI features
- [ ] Task 10: Create unit tests (AC: 7)
  - [ ] Create `tests/unit/test_integrations/test_openrouter.py`
  - [ ] Test: successful API call with mock response
  - [ ] Test: error handling (network errors, API errors)
  - [ ] Test: retry logic
  - [ ] Test: rate limiting
  - [ ] Test: cost calculation
  - [ ] Use `pytest` and `pytest-mock` for mocking
- [ ] Task 11: Create integration test (AC: 8)
  - [ ] Create `tests/integration/test_integrations/test_openrouter_api.py`
  - [ ] Test: call OpenRouter API with sample policy change diff
  - [ ] Verify response structure
  - [ ] Verify token counts logged
  - [ ] Verify cost calculated
  - [ ] Use test API key (not production)

## Dev Notes

### Previous Story Insights
- Story 3.3 created email sending service integration (Resend) - similar pattern
- Story 1.4 created configuration system for environment variables
- Story 1.8 created logging infrastructure

### OpenRouter API
[Source: https://openrouter.ai/]

**OpenRouter Overview:**
- Unified interface for LLMs
- Access to 500+ models across 60+ providers
- OpenAI SDK compatible (works with `openai` Python library)
- Better prices and uptime
- Custom data policies support

**API Details:**
- Base URL: `https://openrouter.ai/api/v1`
- Authentication: Bearer token (`Authorization: Bearer <api_key>`)
- API key stored in `OPENROUTER_API_KEY` environment variable
- OpenAI-compatible endpoints: `/chat/completions`, `/completions`

**Key Features:**
- Model routing (automatic fallback to other providers)
- Higher availability (distributed infrastructure)
- Cost tracking and monitoring
- Custom data policies

**Integration Notes:**
- Use OpenAI Python SDK with OpenRouter base URL
- Set `base_url="https://openrouter.ai/api/v1"` in OpenAI client
- Set `api_key` from environment variable
- Specify model in request (e.g., `anthropic/claude-3-opus`, `openai/gpt-4`)
- Track token usage and costs from API response

### External APIs Pattern
[Source: docs/architecture/external-apis.md]

**Resend API Pattern (Reference):**
- API key from environment variables
- Client abstraction layer
- Error handling and retry logic
- Logging all API calls
- Similar pattern applies to OpenRouter

### File Locations
[Source: docs/architecture/unified-project-structure.md]

Files to create:
- `api/integrations/__init__.py` - Integrations package (if not exists)
- `api/integrations/openrouter.py` - OpenRouter API client
- `api/models/db/llm_api_usage.py` - LLM API usage tracking model
- `api/repositories/llm_api_usage_repository.py` - Usage tracking repository
- `tests/unit/test_integrations/test_openrouter.py` - Unit tests
- `tests/integration/test_integrations/test_openrouter_api.py` - Integration tests
- `alembic/versions/XXX_add_llm_api_usage.py` - Migration for usage tracking

### Coding Standards
[Source: docs/architecture/coding-standards.md]

**External API Integration:**
- Always use abstraction layer for external APIs
- Never call API directly from route handlers or services
- Configuration must be externalized to environment variables
- Never hardcode API keys

**Error Handling:**
- Handle all exceptions gracefully
- Return error status in result objects
- Log errors for debugging

### Tech Stack
[Source: docs/architecture/tech-stack.md]

**LLM Integration:**
- Python 3.10+
- `openai` Python SDK (OpenRouter compatible)
- `httpx` or `requests` for HTTP (if needed)
- `pytest` and `pytest-mock` for testing

### Testing Requirements
[Source: docs/architecture/testing-strategy.md]

**Unit Tests:**
- Test API client with mock responses
- Test error handling
- Test retry logic
- Test rate limiting
- Test cost calculation

**Integration Tests:**
- Test with real OpenRouter API (test key)
- Verify response structure
- Verify token tracking
- Verify cost calculation

### Technical Constraints
- OpenRouter API key must be stored securely (environment variable)
- Must handle API rate limits
- Must track costs for budget management
- Must support graceful degradation if API unavailable
- OpenAI SDK compatibility required

## Testing

**Unit Tests:**
- Test successful API call with mock response
- Test error handling (network errors, API errors)
- Test retry logic
- Test rate limiting
- Test cost calculation

**Integration Tests:**
- Call OpenRouter API with sample policy change diff
- Verify response structure
- Verify token counts logged
- Verify cost calculated

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-27 | 1.0 | Initial story creation | Bob (Scrum Master) |

