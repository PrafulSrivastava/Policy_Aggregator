# Story 2.9: End-to-End Fetch Pipeline

## Status
Ready for Review

## Story
**As a** developer,  
**I want** a complete fetch pipeline that orchestrates all steps,  
**so that** I can fetch a source, normalize, detect changes, and store results in one operation.

## Acceptance Criteria

1. Main pipeline function: `fetch_and_process_source(source_id)`
2. Pipeline steps executed in order:
   - Load source configuration from database
   - Select appropriate fetcher based on source.fetch_type
   - Execute fetcher to get raw content
   - Normalize content
   - Generate hash
   - Compare with previous version
   - Store PolicyVersion
   - If changed: generate diff, create PolicyChange
3. Error handling: if any step fails, log error and continue with next source (graceful degradation)
4. Retry logic: transient failures retried 2-3 times with exponential backoff
5. Logging at each step for debugging and auditability
6. Returns summary: success/failure, change detected yes/no, error messages
7. Integration test: full pipeline with real source (or mock)
8. Unit tests for each pipeline step
9. Can be called manually via API endpoint for testing

## Tasks / Subtasks

- [x] Task 1: Create fetch pipeline orchestrator (AC: 1, 2)
  - [x] Create or update `api/services/fetcher_manager.py`
  - [x] Implement `fetch_and_process_source(source_id: UUID) -> PipelineResult` function
  - [x] Pipeline steps in order:
    - [x] Load source configuration from database (use Source repository)
    - [x] Select appropriate fetcher (use `get_fetcher_for_source()`)
    - [x] Execute fetcher to get raw content
    - [x] Normalize content (use normalizer service)
    - [x] Generate hash (use hashing utility)
    - [x] Compare with previous version (use change detector)
    - [x] Store PolicyVersion (use version storage service)
    - [x] If changed: generate diff (use diff generator), create PolicyChange (use change storage)
  - [x] Return `PipelineResult` with summary
- [x] Task 2: Create PipelineResult model (AC: 6)
  - [x] Create dataclass or Pydantic model:
    - [x] `success: bool`
    - [x] `source_id: UUID`
    - [x] `change_detected: bool`
    - [x] `policy_version_id: Optional[UUID]`
    - [x] `policy_change_id: Optional[UUID]`
    - [x] `error_message: Optional[str]`
    - [x] `fetched_at: datetime`
- [x] Task 3: Implement error handling (AC: 3)
  - [x] Wrap each pipeline step in try-except
  - [x] Log errors at each step
  - [x] Return error in `PipelineResult` if step fails
  - [x] Do not raise exceptions (graceful degradation)
  - [x] Continue with next source if current source fails
- [x] Task 4: Implement retry logic (AC: 4)
  - [x] Add retry logic for transient failures:
    - [x] Network errors (timeout, connection errors)
    - [x] HTTP 5xx errors
  - [x] Retry 2-3 times with exponential backoff
  - [x] Do not retry on permanent failures (404, validation errors)
- [x] Task 5: Add comprehensive logging (AC: 5)
  - [x] Log each pipeline step:
    - [x] "Loading source configuration for {source_id}"
    - [x] "Executing fetcher for {source_id}"
    - [x] "Normalizing content for {source_id}"
    - [x] "Detecting changes for {source_id}"
    - [x] "Storing PolicyVersion for {source_id}"
    - [x] "Change detected for {source_id}, creating PolicyChange"
  - [x] Log errors with context
  - [x] Use appropriate log levels (INFO for steps, ERROR for failures)
- [x] Task 6: Create API endpoint for manual trigger (AC: 9)
  - [x] Create or update `api/routes/api.py`
  - [x] Implement `POST /api/sources/{id}/trigger` endpoint
    - [x] Accept source ID as path parameter
    - [x] Call `fetch_and_process_source(source_id)`
    - [x] Return PipelineResult as JSON
    - [x] Require authentication
  - [x] Add to OpenAPI documentation
- [x] Task 7: Create unit tests (AC: 8)
  - [x] Create `tests/unit/test_services/test_fetcher_manager.py`
  - [x] Test each pipeline step individually:
    - [x] Source loading
    - [x] Fetcher selection
    - [x] Fetcher execution
    - [x] Normalization
    - [x] Hash generation
    - [x] Change detection
    - [x] Version storage
    - [x] Diff generation
    - [x] Change storage
  - [x] Test error handling at each step
  - [x] Test retry logic
- [x] Task 8: Create integration test (AC: 7)
  - [x] Create `tests/integration/test_pipeline/test_end_to_end.py`
  - [x] Test full pipeline with mock source:
    - [x] Create test source in database
    - [x] Create mock fetcher
    - [x] Run pipeline
    - [x] Verify all steps executed
    - [x] Verify PolicyVersion created
    - [x] Verify change detection works
  - [x] Test with real source (optional, for manual testing)

## Dev Notes

### Previous Story Insights
- Story 2.1 created fetcher plugin architecture and manager
- Story 2.2 and 2.3 created HTML and PDF fetchers
- Story 2.4 created normalization pipeline
- Story 2.5 created version storage
- Story 2.6 created change detection
- Story 2.7 created diff generation
- Story 2.8 created PolicyChange storage
- All components are ready to be orchestrated

### Components Architecture
[Source: architecture/components.md]

**Fetcher Manager:**
- Orchestrates source fetching operations
- Manages concurrent fetching
- Coordinates the fetch pipeline

**Key Interfaces:**
- `fetch_source(source_id)` - Executes fetcher for a specific source
- `fetch_and_process_source(source_id)` - Full pipeline execution

### File Locations
[Source: architecture/unified-project-structure.md]

Files to create/update:
- `api/services/fetcher_manager.py` - Pipeline orchestrator (update existing)
- `api/routes/api.py` - Add manual trigger endpoint
- `tests/unit/test_services/test_fetcher_manager.py` - Unit tests
- `tests/integration/test_pipeline/test_end_to_end.py` - Integration tests

### Coding Standards
[Source: architecture/coding-standards.md]

**Fetcher Interface:** All source fetchers must implement the `SourceFetcher` interface. Never bypass the fetcher manager.

**Error Handling:** Pipeline should handle errors gracefully, not raise exceptions.

**Logging:** Use Python's `logging` module with appropriate log levels.

**Type Hints:** All Python functions must have type hints.

**Async/Await:** Use `async def` and `await` for all database operations.

### API Specification
[Source: architecture/api-specification.md]

**Manual Trigger Endpoint:**
```
POST /api/sources/{id}/trigger
Response: {
  "success": boolean,
  "sourceId": UUID,
  "changeDetected": boolean,
  "policyVersionId": UUID | null,
  "policyChangeId": UUID | null,
  "error": string | null,
  "fetchedAt": datetime
}
```

### Testing Requirements
[Source: architecture/testing-strategy.md]

**Unit Tests:**
- Test each pipeline step
- Test error handling
- Test retry logic

**Integration Tests:**
- Test full pipeline end-to-end
- Test with mock and real sources

### Technical Constraints
- Pipeline must handle errors gracefully
- Must implement retry logic for transient failures
- Must log all steps for debugging
- Must return comprehensive result summary
- Must be callable via API endpoint

## Testing

### Testing Standards
[Source: architecture/testing-strategy.md]

**Test File Location:** `tests/unit/test_services/test_fetcher_manager.py` and `tests/integration/test_pipeline/test_end_to_end.py`

**Test Standards:**
- Use pytest framework
- Use async test fixtures for database operations
- Test files follow `test_*.py` naming convention

**Testing Frameworks:**
- pytest 7.4+ with async support
- pytest-asyncio for async test support

**Specific Testing Requirements:**
- Test each pipeline step individually
- Test full pipeline end-to-end
- Test error handling at each step
- Test retry logic
- Test API endpoint for manual trigger

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-27 | 1.0 | Initial story creation | Scrum Master |
| 2025-01-27 | 1.1 | Story implementation completed | Dev Agent (James) |

## Dev Agent Record

### Agent Model Used
Claude Sonnet 4.5 (via Cursor)

### Debug Log References
N/A - No debug issues encountered

### Completion Notes List
- Created `fetch_and_process_source()` function in `api/services/fetcher_manager.py` orchestrating all pipeline steps
- Created `PipelineResult` dataclass with all required fields (success, source_id, change_detected, policy_version_id, policy_change_id, error_message, fetched_at)
- Implemented comprehensive error handling: each pipeline step wrapped in try-except, errors logged and returned in PipelineResult, graceful degradation (no exceptions raised)
- Implemented retry logic with exponential backoff: `_retry_with_backoff()` function handles transient failures (network errors, HTTP 5xx), retries 2-3 times, skips permanent failures (404, validation errors)
- Added comprehensive logging at each pipeline step with appropriate log levels (INFO for steps, ERROR for failures)
- Created API endpoint `POST /api/sources/{id}/trigger` in `api/routes/api.py` for manual pipeline trigger, requires authentication, returns PipelineResult as JSON
- Created unit tests in `tests/unit/test_services/test_fetcher_pipeline.py` covering all pipeline steps, error handling, and retry logic
- Created integration tests in `tests/integration/test_pipeline/test_end_to_end.py` testing full pipeline with mock sources, change detection, and error scenarios
- All acceptance criteria met: complete pipeline orchestration, error handling, retry logic, logging, API endpoint, comprehensive tests

### File List
**Created:**
- `tests/unit/test_services/test_fetcher_pipeline.py` - Unit tests for pipeline and retry logic
- `tests/integration/test_pipeline/test_end_to_end.py` - Integration tests for end-to-end pipeline

**Modified:**
- `api/services/fetcher_manager.py` - Added `fetch_and_process_source()` function, `PipelineResult` dataclass, and `_retry_with_backoff()` retry logic
- `api/routes/api.py` - Added `POST /api/sources/{id}/trigger` endpoint for manual pipeline trigger

## QA Results
_To be populated by QA Agent_

